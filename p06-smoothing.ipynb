{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my helpers!\n",
    "from shared import (\n",
    "    dataset_local_path,\n",
    "    bootstrap_auc,\n",
    "    simple_boxplot,\n",
    ")\n",
    "\n",
    "# stdlib:\n",
    "from dataclasses import dataclass, field\n",
    "import json, gzip\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load up the data\n",
    "# Try 'POETRY'\n",
    "dataset = \"POETRY\"\n",
    "examples: List[str] = []\n",
    "ys: List[bool] = []\n",
    "\n",
    "if dataset == \"WIKI\":\n",
    "    with gzip.open(dataset_local_path(\"lit-wiki-2020.jsonl.gz\"), \"rt\") as fp:\n",
    "        for line in fp:\n",
    "            info = json.loads(line)\n",
    "            # Note: the data contains a whole bunch of extra stuff; we just want numeric features for now.\n",
    "            keep = info[\"body\"]\n",
    "            # whether or not it's poetry is our label.\n",
    "            ys.append(info[\"truth_value\"])\n",
    "            # hold onto this single dictionary.\n",
    "            examples.append(keep)\n",
    "else:\n",
    "    # take only one per book!\n",
    "    by_book = {}\n",
    "    with open(dataset_local_path(\"poetry_id.jsonl\")) as fp:\n",
    "        for line in fp:\n",
    "            info = json.loads(line)\n",
    "            # dictionary keeps this key unique:\n",
    "            by_book[info[\"book\"]] = info\n",
    "    # now extract only one page per book here:\n",
    "    for info in by_book.values():\n",
    "        # Note: the data contains a whole bunch of extra stuff; we just want numeric features for now.\n",
    "        keep = info[\"words\"]\n",
    "        # whether or not it's poetry is our label.\n",
    "        ys.append(info[\"poetry\"])\n",
    "        # hold onto this single dictionary.\n",
    "        examples.append(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Split data:\n",
    "\n",
    "RANDOM_SEED = 1234\n",
    "\n",
    "## split off train/validate (tv) pieces.\n",
    "ex_tv, ex_test, y_tv, y_test = train_test_split(\n",
    "    examples,\n",
    "    ys,\n",
    "    train_size=0.75,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "# split off train, validate from (tv) pieces.\n",
    "ex_train, ex_vali, y_train, y_vali = train_test_split(\n",
    "    ex_tv, y_tv, train_size=0.66, shuffle=True, random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(680, 156207) (351, 156207) (344, 156207)\n"
     ]
    }
   ],
   "source": [
    "#%% Analyze Text\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# Note we're doing \"CountVectorizer\" here and not TfidfVectorizer. Hmm...\n",
    "word_features = CountVectorizer(\n",
    "    strip_accents=\"unicode\",\n",
    "    lowercase=True,\n",
    "    ngram_range=(1, 2),\n",
    ")\n",
    "\n",
    "#The lower and upper boundary of the range of n-values for \n",
    "#different word n-grams or char n-grams to be extracted. \n",
    "#All values of n such such that min_n <= n <= max_n will be used. \n",
    "#For example an ngram_range of (1, 1) means only unigrams, \n",
    "#(1, 2) means unigrams and bigrams, and (2, 2) means only bigrams. Only applies if analyzer is not callable.\n",
    "\n",
    "# How does it take a whole paragraph and turn it into words?\n",
    "text_to_words = word_features.build_analyzer()\n",
    "# text_to_words is a function (str) -> List[str]\n",
    "# assert text_to_words(\"Hello world!\") == [\"hello\", \"world\"]\n",
    "\n",
    "# Learn columns from training data (again)\n",
    "word_features.fit(ex_train)\n",
    "# Translate our list of texts -> matrices of counts\n",
    "X_train = word_features.transform(ex_train)\n",
    "X_vali = word_features.transform(ex_vali)\n",
    "X_test = word_features.transform(ex_test)\n",
    "\n",
    "print(X_train.shape, X_vali.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Accumulate results here; to be box-plotted.\n",
    "results: Dict[str, List[float]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha -  0.1\n",
      "Accuracy: 0.906, AUC: 0.933\n",
      "What I called log(beta)=-1.4851401957565225\n",
      "Alpha -  1\n",
      "Accuracy: 0.855, AUC: 0.869\n",
      "What I called log(beta)=-1.4851401957565225\n",
      "Alpha -  10\n",
      "Accuracy: 0.769, AUC: 0.677\n",
      "What I called log(beta)=-1.4851401957565225\n",
      "Alpha -  100\n",
      "Accuracy: 0.769, AUC: 0.608\n",
      "What I called log(beta)=-1.4851401957565225\n",
      "Alpha -  1000\n",
      "Accuracy: 0.769, AUC: 0.576\n",
      "What I called log(beta)=-1.4851401957565225\n"
     ]
    }
   ],
   "source": [
    "#%% try sklearn MultinomialNB:\n",
    "\n",
    "## SKLearn has it's own Multinomial Naive Bayes,\n",
    "#  and it uses the alpha / additive smoothing to deal with zeros!\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Try a couple alpha values (what to do with zero-prob words!)\n",
    "# Alpha can really be anything positive!\n",
    "for alpha in [0.1,1,10,100,1000]:\n",
    "    m = MultinomialNB(alpha=alpha)\n",
    "    m.fit(X_train, y_train)\n",
    "    scores = m.predict_proba(X_vali)[:, 1]\n",
    "    print(\"Alpha - \", alpha)\n",
    "    print(\n",
    "        \"Accuracy: {:.3}, AUC: {:.3}\".format(\n",
    "            m.score(X_vali, y_vali), roc_auc_score(y_score=scores, y_true=y_vali)\n",
    "        )\n",
    "    )\n",
    "    print(\"What I called log(beta)={}\".format(m.class_log_prior_[1]))\n",
    "    results[\"MNB(alpha={})\".format(alpha)] = bootstrap_auc(m, X_vali, y_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive-size: 84984\n",
      "rand-size: 393281\n"
     ]
    }
   ],
   "source": [
    "#%% Showcase linar smoothing:\n",
    "\n",
    "from collections import Counter\n",
    "import typing\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CountLanguageModel:\n",
    "    \"\"\" The number of times each word has been observed. \"\"\"\n",
    "\n",
    "    counts: typing.Counter[str] = field(default_factory=Counter)\n",
    "    \"\"\" The total number of observed words (any word)\"\"\"\n",
    "    total: int = 0\n",
    "    # Don't need an alpha\n",
    "\n",
    "    def add_example(self, words: List[str]) -> None:\n",
    "        for word in words:\n",
    "            self.counts[word] += 1\n",
    "        self.total += len(words)\n",
    "\n",
    "    def prob(self, word: str) -> float:\n",
    "        return self.counts[word] / self.total\n",
    "\n",
    "\n",
    "# Make one of these for the positive class:\n",
    "is_positive = CountLanguageModel()\n",
    "# Make one of these for ALL documents.\n",
    "is_random = CountLanguageModel()\n",
    "\n",
    "# Train these two model pieces:\n",
    "for y, ex in zip(y_train, ex_train):\n",
    "    words = text_to_words(ex)\n",
    "    # with linear smoothing, everything goes in random (positive OR negative)\n",
    "    is_random.add_example(words)\n",
    "    # but only positive go in positive:\n",
    "    if y:\n",
    "        is_positive.add_example(words)\n",
    "\n",
    "print(\"positive-size: {}\".format(is_positive.total))\n",
    "print(\"rand-size: {}\".format(is_random.total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear[0.01] AUC=0.947\n",
      "Linear[0.5] AUC=0.943\n",
      "Linear[0.99] AUC=0.852\n"
     ]
    }
   ],
   "source": [
    "def score_words(\n",
    "    words: List[str],\n",
    "    linear: float,\n",
    "    positive: CountLanguageModel,\n",
    "    background: CountLanguageModel,\n",
    ") -> float:\n",
    "    score = 0.0\n",
    "    # Compute log-product of word-probabilities:\n",
    "    for word in words:\n",
    "        # prob-yes!\n",
    "        prob_positive = positive.prob(word)\n",
    "        # prob-no!\n",
    "        prob_negative = background.prob(word)\n",
    "        # words that are only in vali/test:\n",
    "        if prob_positive == 0.0 and prob_negative == 0.0:\n",
    "            continue\n",
    "\n",
    "        # mix the positive and negative together (to avoid prob_positive being a zero)\n",
    "        smoothed_positive = (prob_positive * linear) + (prob_negative * (1 - linear))\n",
    "        # multiply up P(yes) / P(no) but logged!\n",
    "        score += math.log(smoothed_positive) - math.log(prob_negative)\n",
    "    return score\n",
    "\n",
    "\n",
    "#\n",
    "# The linear parameter is traditionally a non-zero, non-one probability:\n",
    "#     (0 < linear < 1)\n",
    "for linear in [0.01, 0.5, 0.99]:\n",
    "    scores = []\n",
    "    for ex in ex_vali:\n",
    "        score = score_words(text_to_words(ex), linear, is_positive, is_random)\n",
    "        scores.append(score)\n",
    "\n",
    "    # Note that there's no accuracy because I haven't figured out beta...\n",
    "    print(\n",
    "        \"Linear[{}] AUC={:.3}\".format(\n",
    "            linear, roc_auc_score(y_score=scores, y_true=y_vali)\n",
    "        )\n",
    "    )\n",
    "    # bootstrap AUC: (doing this manually because the helper function doesn't accept scores out of nowhere!)\n",
    "    dist = []\n",
    "    # do the bootstrap:\n",
    "    for trial in range(100):\n",
    "        sample_pred, sample_truth = resample(\n",
    "            scores, y_vali, random_state=trial + RANDOM_SEED\n",
    "        )  # type:ignore\n",
    "        score = roc_auc_score(y_true=sample_truth, y_score=sample_pred)  # type:ignore\n",
    "        dist.append(score)\n",
    "    results[\"Linear[{}]\".format(linear)] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/Users/Alderik/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Boxplot all AUC results:\n",
    "simple_boxplot(results, ylabel=\"AUC\", save=\"{}-text-AUC.png\".format(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Explore alpha and linear parameters; make a decision about what a good choice for this dataset might be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha of .1 and linear parameter of 0.01 were the best from my test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 is once again a choose-your-own:\n",
    "\n",
    "### 2A. Explore ngrams, lowercase v. uppercase, etc. (how changing CountVectorizer changes performance, or not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigrams & Bigrams improved performance (1,2) compared to only Unigrams (1,1)   \n",
    "Only bigrams (2,2) decreased performance compared only unigrams (1,1) and (1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B. Explore the difference between today's approaches to the WIKI dataset and yesterday's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p05 used TFIDFVectorizer instead of p06 using CountVectorizer   \n",
    "p05 used many different linear models and tree models, p06 we use a Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2C. Explore the differences between the WIKI dataset and the POETRY dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the optimized alpha and linear parameter, the poetry dataset gets a much higher AUC and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
